{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic BCI Demo\n",
    "\n",
    "Categorization of cognitive states in real time is important for effective BCI. Here we demonstrate a basic machine learning categorization technique to distinguish between two different thinking tasks. We will show the machine two different brain activities and train a machine learning model. We can then show the machine new data, in real time, and the model will predict which thinking task it is. The support vector machine (ML) is only looking to distinguish between the states, so we donâ€™t get any information about what these states are. Rather, the computer should tell us which state the subject is in, so long as the brain processes associated with each task are significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Module that simplifies computations on matrices\n",
    "import matplotlib.pyplot as plt  # Module used for plotting\n",
    "from pylsl import StreamInlet, resolve_byprop  # Module to receive EEG data\n",
    "\n",
    "import bci_workshop_tools as BCIw  # Our own functions for the workshop\n",
    "import ipython_bell \n",
    "import time\n",
    "print(\"Setup complete.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "win10toast not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\site-packages\\ipython_bell\\notifiers.py\u001b[0m in \u001b[0;36mwindows\u001b[1;34m(self, title, text)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[1;32mfrom\u001b[0m \u001b[0mwin10toast\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mToastNotifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mtoaster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mToastNotifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'win10toast'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1793e229f7c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bell'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-n notify'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2285\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2286\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2287\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2288\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-126>\u001b[0m in \u001b[0;36mbell\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\site-packages\\ipython_bell\\bell.py\u001b[0m in \u001b[0;36mbell\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# call platform appropriate method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\lib\\site-packages\\ipython_bell\\notifiers.py\u001b[0m in \u001b[0;36mwindows\u001b[1;34m(self, title, text)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mtoaster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_toast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'win10toast not installed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: win10toast not installed"
     ]
    }
   ],
   "source": [
    "%matplotlib \n",
    "%bell -n notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for an EEG stream...\n",
      "Start acquiring data\n",
      "\n",
      " Stimuli \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdgri\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'winsound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-0775dfdbc004>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m             feat_matrix0, feat_matrix1, 'SVM')\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mwinsound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;34m\"\"\" 5. USE THE CLASSIFIER IN REAL-TIME\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'winsound' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \"\"\" 1. CONNECT TO EEG STREAM \"\"\"\n",
    "\n",
    "    # Search for active LSL stream\n",
    "    print('Looking for an EEG stream...')\n",
    "    streams = resolve_byprop('type', 'EEG', timeout=2)\n",
    "    if len(streams) == 0:\n",
    "        raise RuntimeError('Can\\'t find EEG stream.')\n",
    "\n",
    "    # Set active EEG stream to inlet and apply time correction\n",
    "    print(\"Start acquiring data\")\n",
    "    inlet = StreamInlet(streams[0], max_chunklen=12)\n",
    "    eeg_time_correction = inlet.time_correction()\n",
    "\n",
    "    # Get the stream info, description, sampling frequency, number of channels\n",
    "    info = inlet.info()\n",
    "    description = info.desc()\n",
    "    fs = int(info.nominal_srate())\n",
    "    n_channels = info.channel_count()\n",
    "\n",
    "    # Get names of all channels\n",
    "    ch = description.child('channels').first_child()\n",
    "    ch_names = [ch.child_value('label')]\n",
    "    for i in range(1, n_channels):\n",
    "        ch = ch.next_sibling()\n",
    "        ch_names.append(ch.child_value('label'))\n",
    "\n",
    "    \"\"\" 2. SET EXPERIMENTAL PARAMETERS \"\"\"\n",
    "\n",
    "    # Length of the EEG data buffer (in seconds)\n",
    "    # This buffer will hold last n seconds of data and be used for calculations\n",
    "    buffer_length = 15\n",
    "\n",
    "    # Length of the epochs used to compute the FFT (in seconds)\n",
    "    epoch_length = 1\n",
    "\n",
    "    # Amount of overlap between two consecutive epochs (in seconds)\n",
    "    overlap_length = 0.8\n",
    "\n",
    "    # Amount to 'shift' the start of each next consecutive epoch\n",
    "    shift_length = epoch_length - overlap_length\n",
    "\n",
    "    # Index of the channel (electrode) to be used\n",
    "    # 0 = left ear, 1 = left forehead, 2 = right forehead, 3 = right ear\n",
    "    index_channel = [0, 1, 2, 3]\n",
    "    # Name of our channel for plotting purposes\n",
    "    ch_names = [ch_names[i] for i in index_channel]\n",
    "    n_channels = len(index_channel)\n",
    "\n",
    "    # Get names of features\n",
    "    # ex. ['delta - CH1', 'pwr-theta - CH1', 'pwr-alpha - CH1',...]\n",
    "    feature_names = BCIw.get_feature_names(ch_names)\n",
    "\n",
    "    # Number of seconds to collect training data for (one class)\n",
    "    training_length = 30\n",
    "\n",
    "    \"\"\" 3. RECORD TRAINING DATA \"\"\"\n",
    "\n",
    "    # Record data for mental activity 0\n",
    "    b.beep(frequency=530, secs=0.7, blocking=True)\n",
    "    eeg_data0, timestamps0 = inlet.pull_chunk(\n",
    "            timeout=training_length+1, max_samples=fs * training_length)\n",
    "    eeg_data0 = np.array(eeg_data0)[:, index_channel]\n",
    "\n",
    "    print('\\n Stimuli \\n')\n",
    "\n",
    "    # Record data for mental activity 1\n",
    "    b.beep(frequency=530, secs=0.7, blocking=True)\n",
    "    eeg_data1, timestamps1 = inlet.pull_chunk(\n",
    "            timeout=training_length+1, max_samples=fs * training_length)\n",
    "    eeg_data1 = np.array(eeg_data1)[:, index_channel]\n",
    "\n",
    "    # Divide data into epochs\n",
    "    eeg_epochs0 = BCIw.epoch(eeg_data0, epoch_length * fs,\n",
    "                             overlap_length * fs)\n",
    "    eeg_epochs1 = BCIw.epoch(eeg_data1, epoch_length * fs,\n",
    "                             overlap_length * fs)\n",
    "\n",
    "    \"\"\" 4. COMPUTE FEATURES AND TRAIN CLASSIFIER \"\"\"\n",
    "\n",
    "    feat_matrix0 = BCIw.compute_feature_matrix(eeg_epochs0, fs)\n",
    "    feat_matrix1 = BCIw.compute_feature_matrix(eeg_epochs1, fs)\n",
    "\n",
    "    [classifier, mu_ft, std_ft] = BCIw.train_classifier(\n",
    "            feat_matrix0, feat_matrix1, 'SVM')\n",
    "\n",
    "    winsound.Beep(600,500)\n",
    "\n",
    "    \"\"\" 5. USE THE CLASSIFIER IN REAL-TIME\"\"\"\n",
    "\n",
    "    # Initialize the buffers for storing raw EEG and decisions\n",
    "    eeg_buffer = np.zeros((int(fs * buffer_length), n_channels))\n",
    "    filter_state = None  # for use with the notch filter\n",
    "    decision_buffer = np.zeros((30, 1))\n",
    "\n",
    "    plotter_decision = BCIw.DataPlotter(30, ['Decision'])\n",
    "\n",
    "    # The try/except structure allows to quit the while loop by aborting the\n",
    "    # script with <Ctrl-C>\n",
    "    print('Press Ctrl-C in the console to break the while loop.')\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "\n",
    "            \"\"\" 3.1 ACQUIRE DATA \"\"\"\n",
    "            # Obtain EEG data from the LSL stream\n",
    "            eeg_data, timestamp = inlet.pull_chunk(\n",
    "                    timeout=1, max_samples=int(shift_length * fs))\n",
    "\n",
    "            # Only keep the channel we're interested in\n",
    "            ch_data = np.array(eeg_data)[:, index_channel]\n",
    "\n",
    "            # Update EEG buffer\n",
    "            eeg_buffer, filter_state = BCIw.update_buffer(\n",
    "                    eeg_buffer, ch_data, notch=True,\n",
    "                    filter_state=filter_state)\n",
    "\n",
    "            \"\"\" 3.2 COMPUTE FEATURES AND CLASSIFY \"\"\"\n",
    "            # Get newest samples from the buffer\n",
    "            data_epoch = BCIw.get_last_data(eeg_buffer,\n",
    "                                            epoch_length * fs)\n",
    "\n",
    "            # Compute features\n",
    "            feat_vector = BCIw.compute_feature_vector(data_epoch, fs)\n",
    "            y_hat = BCIw.test_classifier(classifier,\n",
    "                                         feat_vector.reshape(1, -1), mu_ft,\n",
    "                                         std_ft)\n",
    "            print(y_hat)\n",
    "\n",
    "            decision_buffer, _ = BCIw.update_buffer(decision_buffer,\n",
    "                                                    np.reshape(y_hat, (-1, 1)))\n",
    "\n",
    "            \"\"\" 3.3 VISUALIZE THE DECISIONS \"\"\"\n",
    "            plotter_decision.update_plot(decision_buffer)\n",
    "            plt.pause(0.00001)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "\n",
    "        print('Closed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(600,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
